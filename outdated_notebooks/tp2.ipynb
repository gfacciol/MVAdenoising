{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2: A deeper understanding CNN denoising\n",
    "\n",
    "\n",
    "The objective of this lesson is to study more in detail some of the top CNN image denoising algorithms. \n",
    "\n",
    "We will cover the following topics:\n",
    "* Study some aspects of the DnCNN network\n",
    "* Test FFDNet\n",
    "* The role of the training loss\n",
    "* The noise-to-noise training strategy\n",
    "\n",
    "There are **6 questions** in the notebook and corresponding text areas to fill-in the answers. \n",
    "\n",
    "\n",
    "**Note that** some of the bloks of this notebook take up to three minutes to run on CPU, so be patient.\n",
    "\n",
    "\n",
    "#### Instructions\n",
    "To solve this TP, answer the questions below. Then export the notebook with the answers using  the menu option **File->Download as->HTML**. Send the resulting *html* file by mail to [facciolo@cmla.ens-cachan.fr](mailto:facciolo@cmla.ens-cachan.fr) with subject \"Report tp1 of SURNAME, Name\", by 23/11/2018.  You will receive an acknowledgement of receipt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code for the notebook\n",
    "\n",
    "# Execute code 'cells' like this by clicking on the 'Run' \n",
    "# button or by pressing [shift] + [Enter].\n",
    "\n",
    "# This cell only imports some python packages that will be\n",
    "# used below. It doesn't generate any output. Something similar \n",
    "# applies to the next two or three cells. They only define \n",
    "# functions that are used later.\n",
    "\n",
    "\n",
    "# This notebook can also run on colab (https://colab.research.google.com/)\n",
    "# The following lines install the necessary packages in the colab environment\n",
    "try:\n",
    "    from google.colab import files\n",
    "    !pip install torch==0.4.1\n",
    "    !pip install torchvision\n",
    "    !pip install Pillow==4.0.0\n",
    "    !pip install scikit-image\n",
    "    !pip install hdf5storage\n",
    "\n",
    "    !rm -fr MVAdenoising2018\n",
    "    !git clone  https://github.com/gfacciol/MVAdenoising2018\n",
    "    !cp -r MVAdenoising2018/* .\n",
    "\n",
    "except ImportError:\n",
    "    # %matplotlib notebook\n",
    "    pass\n",
    "\n",
    "\n",
    "# These are all the includes used through the notebook\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import vistools          # image visualization toolbox\n",
    "from   skimage import io # read and write images\n",
    "\n",
    "# global variable for setting the torch.load    map_location\n",
    "if torch.cuda.is_available():\n",
    "    loadmap = {'cuda:0': 'gpu'}\n",
    "else:\n",
    "    loadmap = {'cuda:0': 'cpu'}\n",
    "    \n",
    "#%matplotlib notebook\n",
    "# Autoreload external python modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DnCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by testing some aspects of the DnCNN architecture proposed in:\n",
    "\n",
    "*K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, “Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising,” IEEE Trans. Image Process., vol. 26, no. 7, pp. 3142–3155, Jul. 2017.*\n",
    "\n",
    "The network has several hidden layers, all of them equal: convolution, **batch normalization** and **ReLU activations** and uses **residual learning**. All convolutions have the same size (the authors used 3x3).\n",
    "\n",
    "<img width=700 src=\"https://www.researchgate.net/profile/Yunjin_Chen/publication/306187437/figure/fig4/AS:667093628379148@1536058923422/The-architecture-of-the-proposed-DnCNN-network.png\"/>\n",
    "\n",
    "\n",
    "The module `models` declares the DnCNN network. An instance of the network for grayscale images is created with `model = DnCNN(1,1)` where the parameters `1` indicate the number of input and output channels.\n",
    "The model is made of atomic blocks such as `nn.Conv2d`, whch represents a convolutional layer. Note how the layers are declared in the `__init__` method of each model and then called in `forward`. \n",
    "\n",
    "\n",
    "The implementation of DnCNN can be found in the `models/DnCNN.py` file. The model constructor can be called as follows:\n",
    "\n",
    "```python\n",
    "class DnCNN(nn.Module):\n",
    "    '''PyTorch module for the DnCNN network.'''\n",
    "    def __init__(self, in_channels=1, out_channels=1, num_layers=17, \n",
    "                 features=64, kernel_size=3, residual=True):\n",
    "        '''\n",
    "        Constructor for a DnCNN network.\n",
    "\n",
    "        Args:\n",
    "            - in_channels: input image channels (default 1)\n",
    "            - out_channels: output image channels (default 1)\n",
    "            - num_layers: number of layers (default 17)\n",
    "            - num_features: number of hidden features (default 64)\n",
    "            - kernel_size: size of conv. kernel (default 3)\n",
    "            - residual: use residual learning (default True)\n",
    "\n",
    "        Return: network with randomly initialized weights\n",
    "        '''\n",
    "```\n",
    "\n",
    "A newly created network is initialized with random weights.\n",
    "We also provide you with a function to load pretrained weights\n",
    "\n",
    "```python\n",
    "def DnCNN_pretrained(sigma=30, savefile=None, verbose=False, color=False):\n",
    "    '''\n",
    "    Loads the pretrained weights of DnCNN for grayscale and color images  \n",
    "    from https://github.com/cszn/DnCNN.git\n",
    "\n",
    "    Args:\n",
    "        - sigma   : is the level of noise in range(10,76,5)\n",
    "        - savefile: is the .pt file to save the model weights \n",
    "        - verbose : verbose output\n",
    "        - color   : load the weights for the color networks\n",
    "\n",
    "    Returns:\n",
    "        - DnCNN(1,1) model with 17 layers with the pretrained weights    \n",
    "        or\n",
    "        - DnCNN(3,3) model with 20 layers with the pretrained weights     \n",
    "    '''\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap: Extra credit from TP1 - training of a small DnCNN\n",
    "\n",
    "As an optional assignment, you were asked to train a small DnCNN network with the same receptive field and roughly the same number of parameters than a DCT denoiser with 8x8 patches.\n",
    "\n",
    "In case you didn't do the assignment, you can now load a pre-trained network and compare its results with a pretrained Full DnCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the evolution of the loss\n",
    "from models import DnCNN, CONV_BN_RELU\n",
    "\n",
    "# load last checkpoint\n",
    "sigma   = 30\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_2000.pt', map_location=loadmap)\n",
    "\n",
    "plt.semilogy(net[3], '.-', label='net1 val')\n",
    "plt.semilogy(net[2], '.-', label='net1 train')\n",
    "plt.legend(); plt.xlabel('epoch'); plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the evolution of the results along the epochs for this tiny DnCNN, compare the result with the one of our best DCT denoising network, and with the DnCNN network trained by the authors.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolution of the denoising performance during training\n",
    "from denoising_helpers import test_denoiser, PSNR\n",
    "from models import DCTlike, DnCNN_pretrained\n",
    "from skimage import io\n",
    "from vistools import unzip\n",
    "\n",
    "# load an image and compute noisy one \n",
    "sigm = 30 \n",
    "img_clean = io.imread('datasets/BSD68/test002.png', dtype='float32')\n",
    "img_noisy = img_clean + np.random.normal(0, sigma, img_clean.shape)\n",
    "\n",
    "# outputs list of pairs (image, text)\n",
    "outs   = list()\n",
    "\n",
    "# add noisy and clean images\n",
    "outs.append( (img_noisy, 'noisy') )\n",
    "outs.append( (img_clean, 'clean') )\n",
    "\n",
    "# add results of iterations\n",
    "for i in range(0,2001,500):\n",
    "    print('%d '%i, end='')\n",
    "    net = torch.load('pre-trained-tp2/tiny_DnCNN_%04d.pt' % i, map_location=loadmap)[0]\n",
    "    out = test_denoiser(net, img_noisy, sigma, has_noise=True)[0]\n",
    "    outs.append( (out, 'trained tiny DnCNN - it %d - %f (dB)' % (i, PSNR(out, img_clean)) ) ) \n",
    "\n",
    "\n",
    "# add result of original dct\n",
    "net = DCTlike(8, sigma, initializeDCT=True)\n",
    "out = test_denoiser(net, img_noisy, sigma, has_noise=True)[0]\n",
    "outs.append( (out, 'original dct - %f (dB)' % (PSNR(out, img_clean)) ) )\n",
    "\n",
    "# add result of full DnCNN with trained weights\n",
    "net = DnCNN_pretrained(sigma)\n",
    "out = test_denoiser(net, img_noisy, sigma, has_noise=True)[0]\n",
    "outs.append( (out, 'Full DnCNN - %f (dB)' % (PSNR(out, img_clean)) ) )\n",
    "\n",
    "\n",
    "# show result as a gallery \n",
    "vistools.display_gallery(unzip(outs,0), unzip(outs,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress tests on DnCNN: robustness to changes in $\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider the DnCNN network trained for $\\sigma = \\sigma_0$ and see how it responds to changing $\\sigma$. The following code applies noise of different standard deviation to an image and tests two networks: one trained for $\\sigma_0$ and the other one using the network trained for the closest $\\sigma$. The networks have been pretrained for $\\sigma = 10, 15, ..., 70, 75$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DnCNN, DnCNN_pretrained\n",
    "from denoising_helpers import test_denoiser, PSNR\n",
    "from vistools import unzip\n",
    "\n",
    "# load an image (change the number to test other images)\n",
    "image = io.imread('datasets/BSD68/test002.png', dtype='float32')\n",
    "\n",
    "# set a noise level\n",
    "sigma0 = 30\n",
    "\n",
    "im_clean = image.astype('float32')\n",
    "noise = np.random.normal(0, 1., im_clean.shape)\n",
    "\n",
    "# load pre-trained DnCNN\n",
    "dncnn_sigma0 = DnCNN_pretrained(sigma0)\n",
    "\n",
    "sigmas = np.linspace(10,75,14)   #sigmas = np.linspace(5,80,76)\n",
    "#print(sigmas)\n",
    "\n",
    "PSNR_dncnn_sigma0 = list()\n",
    "PSNR_dncnn_sigma  = list()\n",
    "# outputs list of pairs (image, text)\n",
    "outputs = list()\n",
    "\n",
    "# apply them to the image\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    print('%d '%i, end='')\n",
    "    \n",
    "    # add noise\n",
    "    im_noisy = im_clean + sigma * noise\n",
    "\n",
    "    # load correct model\n",
    "    dncnn_sigma = DnCNN_pretrained(sigma)\n",
    "    \n",
    "    # denoise image with both models\n",
    "    out_sigma0 = test_denoiser(dncnn_sigma0, im_noisy, None, has_noise=True)[0]\n",
    "    out_sigma  = test_denoiser(dncnn_sigma , im_noisy, None, has_noise=True)[0] \n",
    "    \n",
    "    PSNR_dncnn_sigma0.append( PSNR(out_sigma0, im_clean) )\n",
    "    PSNR_dncnn_sigma.append(  PSNR(out_sigma , im_clean) )\n",
    "    \n",
    "    outputs.append( (out_sigma0, 'noise sigma = %f - model sigma = %f - PSNR = %f' %(sigma, sigma0, PSNR_dncnn_sigma0[i])) )    \n",
    "    outputs.append( (out_sigma,  'noise sigma = %f - model sigma = %f - PSNR = %f' %(sigma, sigma,  PSNR_dncnn_sigma[i])) ) \n",
    "    \n",
    "# show as a gallery\n",
    "if len(outputs)/2 < 20:\n",
    "    vistools.display_gallery(unzip(outputs,0), unzip(outputs,1))\n",
    "\n",
    "plt.plot(sigmas, PSNR_dncnn_sigma0, '.-', label='model with sigma0')\n",
    "plt.plot(sigmas, PSNR_dncnn_sigma , '.-', label='model with correct sigma')\n",
    "plt.legend(); plt.xlabel('sigma'); plt.ylabel('PSNR (dB)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is reasonable. Note that the denoising images obtained with a fixed $\\sigma_0$ are oversmoothed when $\\sigma < \\sigma_0$ and increasingly noisy for $\\sigma > \\sigma_0$. In both cases the PSNR is below the one obtained for the correct $\\sigma$. The bumps in the curve with the correct sigma are due to the quantization values of pretrained networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress tests on DnCNN: shifting the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we study the performance of the DnCNN algorithm as the intensity range of the input image $u$ is shifted. \n",
    "\n",
    "For that we will take an image $u$ and first reduce its initial intensity range [0,255] by a constant factor of 5 in order to obtain an image with values in the range [0, 51]. This reduced range allows to shift the intensty without saturating. The intensity of this image can then be shifted by a constant $b \\in [0,200]$: $$\\widetilde u = u/5 + b.$$ \n",
    "This range of $b$ assures that $\\widetilde u$ is in the range [0,255].  For this experiment we will fix $\\sigma_0=10$. \n",
    "\n",
    "**Question 1.** <!-- Use the code of the previous block as inspiration for--> The following code creates a plot of the PSNR as a function of $b$ for values of $b \\in [0,200]$ (`bs = np.linspace(0,200,12)`). What can you say about the denoiser performance? In a second plot explore more extreme intensity shifts with $b \\in [-50, 230]$ (`bs = np.linspace(-50,230,14)`). Can you explain the result?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWERS TO QUESTION 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from models import DnCNN, DnCNN_pretrained\n",
    "from denoising_helpers import *\n",
    "from vistools import unzip\n",
    "\n",
    "# load an image (change the number to test other images)\n",
    "image = io.imread('datasets/BSD68/test004.png', dtype='float32')\n",
    "\n",
    "# set a noise level\n",
    "sigma0 = 10\n",
    "noise = np.random.normal(0., 1., image.shape)\n",
    "scale = 5\n",
    "\n",
    "# load pre-trained DnCNN\n",
    "dncnn_sigma0 = DnCNN_pretrained(sigma0)\n",
    "\n",
    "bs = np.linspace(0,200,12)\n",
    "#bs = np.linspace(-50,230,14)\n",
    "\n",
    "PSNR_dncnn_sigma_shift = list() \n",
    "# outputs list of pairs (image, text)\n",
    "outputs = list()\n",
    "\n",
    "# apply them to the image\n",
    "for i, b in enumerate(bs):\n",
    "    print('%d '%i, end='')\n",
    "\n",
    "    # scale clean image and add noise\n",
    "    im_clean = image/scale + b\n",
    "    im_noisy = im_clean + sigma0 * noise\n",
    "     \n",
    "    # denoise image and compute PSNR\n",
    "    out_sigma0 = test_denoiser(dncnn_sigma0, im_noisy, None, has_noise=True)[0]\n",
    "    PSNR_dncnn_sigma_shift.append( PSNR(out_sigma0, im_clean) )\n",
    "    outputs.append( ( (out_sigma0-b)*scale , 'b = %f - sigma = %f - PSNR = %f' % (b, sigma0, PSNR_dncnn_sigma_shift[i])) )\n",
    "\n",
    "\n",
    "######\n",
    "###### NOTE THAT in the gallery the images are scaled back to the range [0,255]   \n",
    "######\n",
    "\n",
    "# show as a gallery\n",
    "if len(outputs) < 80:\n",
    "    vistools.display_gallery( unzip(outputs,0), unzip(outputs,1) )\n",
    "\n",
    "plt.plot(bs, PSNR_dncnn_sigma_shift, '.-', label='model with sigma0')\n",
    "plt.legend(); plt.xlabel('b'); plt.ylabel('PSNR (dB)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress tests on DnCNN: affine scalings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we only have a pre-trained network for a noise level $\\sigma_0$. We would like to denoise an image $u$ contaminated with $\\sigma$. We can apply an affine scale change to our image so that the standard deviation of the noise becomes $\\sigma_0$:\n",
    "$$u_s = \\frac{\\sigma_0}{\\sigma}(u - \\overline{u}) + \\overline{u} = \\frac{\\sigma_0}{\\sigma}u + \\overline{u}\\left(1 - \\frac{\\sigma_0}{\\sigma}\\right) = \\alpha u + \\beta,$$\n",
    "where $\\overline u$ is the average gray level of $u$. The constant $\\beta$ was added so that $\\overline u_s = \\overline u$. The idea is then to apply the denoising network to $u_s$ and then invert the affine transformation:\n",
    "\n",
    "$$\\hat u = \\frac1\\alpha \\mathcal{F}_{\\sigma_0}(\\alpha u + \\beta) - \\frac\\beta\\alpha.$$\n",
    "\n",
    "\n",
    "In the following experiment we will study how the results of the network vary with $\\sigma$.\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**Attention:** For performance reasons, the variables `PSNR_dncnn_sigma0` and `PSNR_dncnn_sigma` of this block are re-used from the block: *\"Stress tests on DnCNN: robustness to changes in $\\sigma$\"*, that was executed before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DnCNN, DnCNN_pretrained\n",
    "from denoising_helpers import *\n",
    "from vistools import unzip\n",
    "\n",
    "# load an image (change the number to test other images)\n",
    "image = io.imread('datasets/BSD68/test002.png', dtype='float32')\n",
    "\n",
    "# set a noise level\n",
    "sigma0 = 30\n",
    "\n",
    "im_clean = image.astype('float32')\n",
    "noise = np.random.normal(0, 1., im_clean.shape)\n",
    "\n",
    "# load pre-trained DnCNN\n",
    "dncnn_sigma0 = DnCNN_pretrained(sigma0)\n",
    "\n",
    "sigmas = np.linspace(10,75,14)  #sigmas = np.linspace(5,80,76)\n",
    "#print(sigmas)\n",
    "\n",
    "##############\n",
    "### THE PSNR_dncnn_sigma0 and PSNR_dncnn_sigma VARIABLES ARE COMPUTED IN SECTION: \n",
    "###    Stress tests on DnCNN: robustness to changes in $\\sigma$ \n",
    "##############\n",
    "\n",
    "#PSNR_dncnn_sigma0 = list()\n",
    "#PSNR_dncnn_sigma  = list()\n",
    "PSNR_dncnn_scaled = list() \n",
    "\n",
    "outputs = list()\n",
    "\n",
    "# apply them to the image\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    print('%d '%i, end='')\n",
    "    \n",
    "    # add noise\n",
    "    im_noisy = im_clean + sigma * noise\n",
    "\n",
    "    # load correct model\n",
    "    dncnn_sigma = DnCNN_pretrained(sigma)\n",
    "    \n",
    "    # denoise image with both models\n",
    "    #out_sigma0 = test_denoiser(dncnn_sigma0, im_noisy, None, has_noise=True)[0]\n",
    "    #out_sigma  = test_denoiser(dncnn_sigma , im_noisy, None, has_noise=True)[0]\n",
    "    \n",
    "    # scaling to match model noise level\n",
    "    a = sigma0/sigma\n",
    "    b = np.mean(im_noisy)*(1-a)\n",
    "    out_scaled = test_denoiser(dncnn_sigma0, a*im_noisy + b, None, has_noise=True)[0]\n",
    "    out_scaled = 1/a*out_scaled - b/a\n",
    "    \n",
    "    #PSNR_dncnn_sigma0.append(PSNR(out_sigma0, im_clean))\n",
    "    #PSNR_dncnn_sigma .append(PSNR(out_sigma , im_clean))\n",
    "    PSNR_dncnn_scaled.append(PSNR(out_scaled, im_clean))\n",
    "\n",
    "    #outputs.append( (out_sigma0, 'noise sigma = %f - model sigma = %f - PSNR = %f' % (sigma, sigma0, PSNR_dncnn_sigma0[i])) )\n",
    "    #outputs.append( (out_sigma,  'noise sigma = %f - model sigma = %f - PSNR = %f' % (sigma, sigma , PSNR_dncnn_sigma [i])) )\n",
    "    outputs.append( (out_scaled, 'noise sigma = %f - scaled to sigma %f - PSNR = %f' % (sigma, sigma , PSNR_dncnn_scaled[i])) )\n",
    "    \n",
    "    \n",
    "# show as a gallery\n",
    "if len(outputs) < 80:\n",
    "    vistools.display_gallery( unzip(outputs,0), unzip(outputs,1) )\n",
    "\n",
    "plt.plot(sigmas, PSNR_dncnn_sigma0, '.-', label='model with sigma0')\n",
    "plt.plot(sigmas, PSNR_dncnn_sigma , '.-', label='model with correct sigma')\n",
    "plt.plot(sigmas, PSNR_dncnn_scaled, '.-', label='model with sigma0, scaled input')\n",
    "plt.legend(); plt.xlabel('sigma'); plt.ylabel('PSNR (dB)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the $\\Delta PSNR$ between the *scaled input* and *correct sigma* outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deltaPSNR = np.array(PSNR_dncnn_sigma) - np.array(PSNR_dncnn_scaled)\n",
    "\n",
    "plt.plot(sigmas, deltaPSNR, '.-', label = 'PSNR correct sigma - PSNR scaled')\n",
    "plt.legend(); plt.xlabel('sigma'); plt.ylabel('Delta PSNR (dB)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Can you explain the behavior of the method with scaled input for sigma>=30? What about sigma<30? Do  you see a way to obtain a method with good performance over a wider range of sigma values? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER TO QUESTION 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The case of DCT denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the case of the DCT denoising. The DCT is a change of basis in the space of patches. The DCT basis is orthonormal, and let us denote it by $\\mathcal B = \\{b_1, ..., b_d\\}$, where $d$ is the dimension of the patches. We can express the DCT denoising of a patch as:\n",
    "$$\\text{DCT}_{\\sigma_0}(P_x u) = \\langle P_xu, b_1\\rangle b_1 + \\sum_{i=2}^d S\\left(\\langle P_xu,b_i\\rangle,\\sigma_0\\right) b_i,$$\n",
    "where $S$ is a shrinkage operator of parameter $\\sigma_0$. For example, the hard-thresholding operator is given by\n",
    "$$S_{\\text{hard}}(x,\\sigma_0) = \n",
    "\\left\\{\n",
    "\\begin{array}{l l}\n",
    "x & \\text{if } x \\geq 3\\sigma_0, \\\\\n",
    "0 & \\text{if } x  < 3\\sigma_0.\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "Suppose we want to denoise an image corrupted with noise $\\sigma$, but instead of using the DCT denoiser with parameters corresponding to $\\sigma_0$, we can only use the DCT denoiser for $\\sigma_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Show that \n",
    "$$\\text{DCT}_{\\sigma_0/\\alpha}(P_x u) = \\text{DCT}_{\\sigma_0}(\\alpha u)\\,/\\,\\alpha$$\n",
    "and that \n",
    "$$\\text{DCT}_{\\sigma_0}(P_x u) + \\beta \\mathbf{1} = DCT_{\\sigma_0}(P_xu + \\beta\\mathbf 1),$$\n",
    "where $\\alpha,\\beta\\in \\mathbb R$ and $\\mathbf 1 = (1,1,...,1)^T\\in \\mathbb R^d$ refers to a constant patch of ones. <!--Use this property to denoise an image with noise $\\sigma$ with $\\text{DCT}_{\\sigma_0}$.-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER TO QUESTION 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following experiment uses this property to denoise an image with noise $\\sigma$ with $\\text{DCT}_{\\sigma_0}$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DCTlike\n",
    "from denoising_helpers import *\n",
    "from vistools import unzip\n",
    "\n",
    "# load an image (change the number to test other images)\n",
    "image = io.imread('datasets/BSD68/test002.png', dtype='float32')\n",
    "\n",
    "# set a noise level\n",
    "sigma0 = 30\n",
    "\n",
    "im_clean = image.astype('float32')\n",
    "noise = np.random.normal(0, 1., im_clean.shape)\n",
    "\n",
    "# load pre-trained DnCNN\n",
    "dct_sigma0 = DCTlike(8, sigma0, True)\n",
    "\n",
    "sigmas = np.linspace(10,75,14) #sigmas = np.linspace(5,80,76)\n",
    "#print(sigmas)\n",
    "\n",
    "PSNR_sigma0 = np.zeros(len(sigmas))\n",
    "PSNR_sigma  = np.zeros(len(sigmas))\n",
    "PSNR_scaled = np.zeros(len(sigmas))\n",
    "\n",
    "outputs = list()\n",
    "\n",
    "# apply them to the image\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    print('%d '%i, end='')\n",
    "    \n",
    "    # add noise\n",
    "    im_noisy = im_clean + sigma * noise\n",
    "\n",
    "    # load correct model\n",
    "    dct_sigma = DCTlike(8, sigma, True)\n",
    "    \n",
    "    # denoise image with both models\n",
    "    out_sigma0 = test_denoiser(dct_sigma0, im_noisy, None, has_noise=True)[0]\n",
    "    out_sigma  = test_denoiser(dct_sigma , im_noisy, None, has_noise=True)[0]\n",
    "    \n",
    "    # scaling to match model noise level\n",
    "    a = sigma0/sigma\n",
    "    b = np.mean(im_noisy)*(1-a)\n",
    "    out_scaled = test_denoiser(dct_sigma0, a*im_noisy + b, None, has_noise=True)[0]\n",
    "    out_scaled = 1/a*out_scaled - b/a\n",
    "    \n",
    "    PSNR_sigma0[i] = PSNR(out_sigma0, im_clean)\n",
    "    PSNR_sigma [i] = PSNR(out_sigma , im_clean)\n",
    "    PSNR_scaled[i] = PSNR(out_scaled, im_clean)\n",
    "\n",
    "    outputs.append( (out_sigma0,'noise sigma = %f - model sigma = %f - PSNR = %f' % (sigma, sigma0, PSNR_sigma0[i])) )\n",
    "    outputs.append( (out_sigma ,'noise sigma = %f - model sigma = %f - PSNR = %f' % (sigma, sigma , PSNR_sigma [i])) )\n",
    "    outputs.append( (out_scaled,'noise sigma = %f - scaled to sigma %f - PSNR = %f' % (sigma, sigma , PSNR_scaled[i])) )\n",
    "    \n",
    "    \n",
    "# show as a gallery\n",
    "if len(outputs) < 80:\n",
    "    vistools.display_gallery( unzip(outputs,0), unzip(outputs,1) )\n",
    "\n",
    "plt.plot(sigmas, PSNR_sigma0, '.-', label='model with sigma0')\n",
    "plt.plot(sigmas, PSNR_sigma , '.-', label='model with correct sigma')\n",
    "plt.plot(sigmas, PSNR_scaled, '.-', label='model with sigma0, scaled input')\n",
    "plt.legend(); plt.xlabel('sigma'); plt.ylabel('PSNR (dB)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFDNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now study FFDNet proposed as an improvement to DnCNN by the same group:\n",
    "\n",
    "*K. Zhang, W. Zuo, and L. Zhang, “FFDNet: Toward a Fast and Flexible Solution for {CNN} based Image Denoising,” CoRR, vol. abs/1710.0, 2017.*\n",
    "\n",
    "<img width=700 src=\"https://raw.githubusercontent.com/gfacciol/MVAdenoising2018/master/models/ffdnet.png\"/>\n",
    "\n",
    "FFDNet consist of a small version of DnCNN, but it has two main differences. The first is the introduction of a noise variance map as an additional input. This map is an image $\\sigma(x)$ that specifies the variance of the noise at location $x$. This allows treating noise with space-varying variance. The second difference is that an invertible downscaling transform is applied to the input image. This downscaling is in fact a re-ordering of the pixels of a $W\\times H$ image as a 4-channel $W/2\\times H/2$ images.\n",
    "\n",
    "The implementation of FFDNet can be found in the `models/FFDNet.py` file. The model constructor can be called as follows:\n",
    "\n",
    "```python\n",
    "class FFDNet(nn.Module):\n",
    "    def __init__(self, sigma=30/255, in_channels=1, out_channels=1, num_layers=15, \n",
    "                 features=64, kernel_size=3):\n",
    "        '''\n",
    "        Model for a FFDNet network build using CONV_BN_RELU units\n",
    "        this network can handle any level of noise when sigma_map is provided.\n",
    "\n",
    "        Args:\n",
    "            - sigma       : default noise level when no sigma_map is given\n",
    "            - in_channels : number of input image channels\n",
    "            - out_channels: number of output image channels\n",
    "            - num_layers  : number of layers of the inner DnCNN network\n",
    "            - features    : number of features of hidden layers in the inner DnCNN net\n",
    "            - kernel_size : kernel size for all layers in the inner DnCNN net\n",
    "        '''\n",
    "```\n",
    "\n",
    "We provide you with a function to load pretrained weights\n",
    "```python\n",
    "    def FFDNet_pretrained_grayscale(sigma=30, savefile=None, verbose=False):\n",
    "        '''\n",
    "        Loads the pretrained weights of FFDNet for grayscale images from \n",
    "        https://github.com/cszn/FFDNet.git\n",
    "\n",
    "        Args:\n",
    "            - sigma   : is the default noise level for the network when sigma_map is not specified\n",
    "            - savefile: is the .pt file to save the model weights \n",
    "            - verbose : verbose output\n",
    "            \n",
    "        Returns:\n",
    "            - FFDNet(1,1) model with 15 layers with the pretrained weights\n",
    "        '''\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise image with both models\n",
    "\n",
    "from models import FFDNet, FFDNet_pretrained_grayscale\n",
    "from models import DnCNN, DnCNN_pretrained\n",
    "from skimage import io\n",
    "from denoising_helpers import test_denoiser\n",
    "\n",
    "sigma=5\n",
    "im_clean = io.imread('datasets/BSD68/test020.png', dtype='float32') \n",
    "im_noisy = im_clean + np.random.normal(0, sigma, im_clean.shape)\n",
    "\n",
    "ffdnet = FFDNet_pretrained_grayscale(sigma)\n",
    "dncnn  = DnCNN_pretrained(sigma)\n",
    "\n",
    "outputs = list()\n",
    "\n",
    "outputs.append( (im_noisy, 'noisy input with sigma = %f' % (sigma)) )\n",
    "outputs.append( (im_clean, 'clean image') )\n",
    "\n",
    "out = test_denoiser(dncnn, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append( (out, 'dncnn output - PSNR = %f' % PSNR(out, im_clean)) )\n",
    "\n",
    "out = test_denoiser(ffdnet, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append( (out, 'ffdnet output - PSNR = %f' % PSNR(out, im_clean)) )\n",
    "\n",
    "vistools.display_gallery(unzip(outputs,0), unzip(outputs,1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will repeat the experiment that we did before and compare the performance of DnCNN and FFDNet when varying the noise level. For DnCNN we compute the result with a network trained with the correct noise level $\\sigma$ and with a fixed noise level $\\sigma_0$. Analogously, for FFDNet we compute the result with a noise map having the correct value \n",
    "$\\sigma$ and one having a fixed noise level $\\sigma_0$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**Attention:** For performance reasons, the variables `PSNR_dncnn_sigma0` and `PSNR_dncnn_sigma` of this block are re-used from the block: *\"Stress tests on DnCNN: robustness to changes in $\\sigma$\"*, that was executed before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from models import DnCNN, DnCNN_pretrained\n",
    "from models import FFDNet, FFDNet_pretrained_grayscale\n",
    "from denoising_helpers import *\n",
    "from skimage import io\n",
    "from vistools import unzip\n",
    "\n",
    "# load an image (change the number to test other images)\n",
    "image = io.imread('datasets/BSD68/test002.png', dtype='float32')\n",
    "\n",
    "# set a noise level\n",
    "sigma0 = 30\n",
    "\n",
    "im_clean = image.astype('float32')\n",
    "noise = np.random.normal(0, 1., im_clean.shape)\n",
    "\n",
    "# load pre-trained DnCNN\n",
    "dncnn_sigma0  =  DnCNN_pretrained(sigma0)\n",
    "ffdnet = FFDNet_pretrained_grayscale(sigma0)\n",
    "\n",
    "sigmas = np.linspace(10,75,14)  #sigmas = np.linspace(5,80,76)\n",
    "#print(sigmas)\n",
    "\n",
    "##############\n",
    "### THE PSNR_dncnn_sigma0 and PSNR_dncnn_sigma VARIABLES ARE COMPUTED IN SECTION: \n",
    "###    Stress tests on DnCNN: robustness to changes in $\\sigma$ \n",
    "##############\n",
    "\n",
    "#PSNR_dncnn_sigma0  = np.zeros(len(sigmas))\n",
    "#PSNR_dncnn_sigma   = np.zeros(len(sigmas))\n",
    "PSNR_ffdnet_sigma0 = np.zeros(len(sigmas))\n",
    "PSNR_ffdnet_sigma  = np.zeros(len(sigmas))\n",
    "\n",
    "outputs = list()\n",
    "\n",
    "# apply them to the image\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    print('%d '%i, end='')\n",
    "    \n",
    "    # add noise\n",
    "    im_noisy = im_clean + sigma * noise\n",
    "\n",
    "    # denoise image with both DnCNN models\n",
    "    dncnn_sigma = DnCNN_pretrained(sigma)\n",
    "    #out_dncnn_sigma0 = test_denoiser(dncnn_sigma0, im_noisy, None, has_noise=True)[0]\n",
    "    #out_dncnn_sigma  = test_denoiser(dncnn_sigma , im_noisy, None, has_noise=True)[0] \n",
    "\n",
    "    # denoise image with both FFDnet models\n",
    "    out_ffdnet_sigma0 = test_denoiser(ffdnet, im_noisy, sigma0, has_noise=True, sigma_param=True)[0]\n",
    "    out_ffdnet_sigma  = test_denoiser(ffdnet, im_noisy, sigma , has_noise=True, sigma_param=True)[0]\n",
    "    \n",
    "    #PSNR_dncnn_sigma0[i]  = PSNR(out_dncnn_sigma0 , im_clean)\n",
    "    #PSNR_dncnn_sigma[i]   = PSNR(out_dncnn_sigma  , im_clean)\n",
    "    PSNR_ffdnet_sigma0[i] = PSNR(out_ffdnet_sigma0, im_clean)\n",
    "    PSNR_ffdnet_sigma[i]  = PSNR(out_ffdnet_sigma , im_clean)\n",
    "\n",
    "    #outputs.append((out_dncnn_sigma0 , 'noise sigma = %4.1f - dncnn  sigma = %4.1f - PSNR = %5.2f' % (sigma, sigma0, PSNR_dncnn_sigma0 [i])))\n",
    "    outputs.append((out_ffdnet_sigma0, 'noise sigma = %4.1f - ffdnet sigma = %4.1f - PSNR = %5.2f' % (sigma, sigma0, PSNR_ffdnet_sigma0[i])))\n",
    "    #outputs.append((out_dncnn_sigma  , 'noise sigma = %4.1f - dncnn  sigma = %4.1f - PSNR = %5.2f' % (sigma, sigma , PSNR_dncnn_sigma  [i])))\n",
    "    outputs.append((out_ffdnet_sigma , 'noise sigma = %4.1f - ffdnet sigma = %4.1f - PSNR = %5.2f' % (sigma, sigma , PSNR_ffdnet_sigma [i])))\n",
    "    \n",
    "    \n",
    "# show as a gallery\n",
    "if len(outputs) < 80:\n",
    "    vistools.display_gallery(unzip(outputs,0), unzip(outputs,1) )\n",
    "\n",
    "plt.figure(figsize=(18, 16))\n",
    "plt.plot(sigmas, PSNR_dncnn_sigma0 , '.-', label='dncnn with sigma0')\n",
    "plt.plot(sigmas, PSNR_dncnn_sigma  , '.-', label='dncnn with correct sigma')\n",
    "plt.plot(sigmas, PSNR_ffdnet_sigma0, '.-', label='ffdnet with sigma0')\n",
    "plt.plot(sigmas, PSNR_ffdnet_sigma , '.-', label='ffdnet with correct sigma')\n",
    "\n",
    "plt.plot(sigmas, PSNR_dncnn_scaled  , '.-', label='dncnn with scaled sigma')\n",
    "plt.legend(); plt.xlabel('sigma'); plt.ylabel('PSNR (dB)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the PSNR for FFDNet is only slightly higher than the one of DnCNN with the correct sigma, or the scaled DnCNN. The advantage of FFDNet is its efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The choice of the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our following experiments deal with the choice of the loss. There are several losses to choose from, and this choice has an impact on the results. [This paper](https://arxiv.org/abs/1511.08861) presents an empirical study of different losses for the application of denoising. \n",
    "\n",
    "We will investigate some properties of the $L_1$ and the squared $L_2$ losses. In addition to the Gaussian noise model that we have used so far, we will introduce a different type of noise that help to highlight some of the differences between these loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform salt and pepper noise\n",
    "\n",
    "The salt and pepper noise contaminates a random set of pixels of an image. A corrupted pixel can take the value 0 or 255, chosen randomly (hence the name salt and pepper). \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f4/Noise_salt_and_pepper.png\"/>\n",
    "\n",
    "In our uniform salt and pepper noise a pixel is corrupted with probability $p$. The corrupted pixels are replaced with a value drawn from a uniform distribution in $[0,255]$. If we denote by $v(x)$ the corrupted pixel and $u(x)$ the clean pixel, the PDF of $v(x)$ given $u(x)$ is:\n",
    "\n",
    "$$P(v(x)\\,|\\,u(x)) = (1-p)\\delta_{u(x)} + p.$$\n",
    "\n",
    "In practice with `numpy` we can corrupt an image with this noise with the following code:\n",
    "```python\n",
    "# binary mask of corrupted pixels (0 means corrupted)\n",
    "mask = np.random.binomial(1, 1-p, im_clean.shape)\n",
    "\n",
    "# image of uniform noise in [0, 255]\n",
    "noise = np.random.uniform(0., 255., im_clean.shape)\n",
    "\n",
    "# replace corrupted pixels with uniform noise\n",
    "im_noisy = im_clean * mask + noise * (1 - mask)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "We have implemented a data loader for training which currupts images with the uniform salt-and-pepper noise. The following code demonstrates its usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from denoising_dataloaders import train_val_denoising_dataloaders\n",
    "import vistools\n",
    "\n",
    "# noise level\n",
    "p = 0.4\n",
    "\n",
    "# create the data loader - note 'noise_type' argument\n",
    "train_loader, val_loader = \\\n",
    "    train_val_denoising_dataloaders('./datasets/Train400/',\n",
    "                                     noise_sigma=p,\n",
    "                                     crop_size=40,\n",
    "                                     train_batch_size=16,\n",
    "                                     noise_type='uniform-sp')\n",
    "\n",
    "# visualize first mini-batch\n",
    "X, Y = list(train_loader)[0]\n",
    "\n",
    "# this helper function displays the patches in the mini-batch\n",
    "print('\\n\\nA minibatch of noisy patches:')\n",
    "vistools.display_patches(X)\n",
    "\n",
    "print('\\n\\nAnd the corresponding noiseless patches:')\n",
    "vistools.display_patches(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Compute the cummulative distribution function (CDF) of $v(x)\\,|\\,u(x)$ and mean and median. The median of a random variable $X$ is defined as the value $m$ such that \n",
    "\n",
    "$$P(X \\geq m) \\geq 1/2\\quad\\text{and}\\quad P(X\\leq m)\\leq 1/2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER TO QUESTION 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian noise denoisers trained with $L_1$ and $L_2$ losses\n",
    "\n",
    "We have trained our tiny DnCNN network with the MSE (or squared L2 loss) and the L1 loss. The following block does the training. We will skip this block, load the pretrained networks, and compare the results on a test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DnCNN\n",
    "from denoising_dataloaders import train_val_denoising_dataloaders\n",
    "from training import trainmodel\n",
    "\n",
    "sigma=30\n",
    "\n",
    "# DO NOT set this flag to true if running on the server.\n",
    "# The results are already pre-computed.\n",
    "training=False\n",
    "\n",
    "# choose loss\n",
    "loss_name = 'l1'\n",
    "#loss_name = 'l2'\n",
    "\n",
    "if training:\n",
    "    # data\n",
    "    trainloader, validationloader = train_val_denoising_dataloaders(\n",
    "                                              './datasets/Train400/', \n",
    "                                               noise_sigma=sigma, crop_size=40, \n",
    "                                               train_batch_size=128)\n",
    "    # network model\n",
    "    dncnn = DnCNN(in_channels=1, out_channels=1, \n",
    "                  num_layers=7, features=13, kernel_size=3, residual=True)\n",
    "    \n",
    "    # run the training loop using chosen loss\n",
    "    loss_fn = nn.L1Loss() if loss_name == 'l1' else nn.MSELoss()\n",
    "    dncnn, losst, lossv = trainmodel(dncnn, loss_fn, trainloader, validationloader, \n",
    "                                     num_epochs=2000, save_every=500, loss_every=100,  \n",
    "                                     learning_rate=0.01, weight_decay=0.00001,\n",
    "                                     filename='pre-trained-tp2/tiny_DnCNN_%s_' % (loss_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise image with both models\n",
    "from models import DnCNN\n",
    "from skimage import io\n",
    "from denoising_helpers import test_denoiser, PSNR\n",
    "from vistools import unzip\n",
    "\n",
    "sigma=30\n",
    "im_clean = io.imread('datasets/BSD68/test002.png', dtype='float32') \n",
    "im_noisy = im_clean + np.random.normal(0, sigma, im_clean.shape)\n",
    "\n",
    "outputs = list()\n",
    "\n",
    "outputs.append((im_noisy, 'noisy input with sigma = %f' % (sigma)))\n",
    "outputs.append((im_clean, 'clean image'))\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_l2_2000.pt', map_location=loadmap)[0]\n",
    "out = test_denoiser(net, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append((out, 'dncnn MSE loss - PSNR = %f' % PSNR(out, im_clean)))\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_l1_2000.pt', map_location=loadmap)[0]\n",
    "out = test_denoiser(net, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append((out, 'dncnn l1 loss - PSNR = %f' % PSNR(out, im_clean)))\n",
    "\n",
    "# show as a gallery\n",
    "vistools.display_gallery(unzip(outputs,0), unzip(outputs,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Give a brief qualitative comparison of the two results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER TO QUESTION 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform salt-and-pepper noise denoisers trained with $L_1$ and $L_2$ losses\n",
    "\n",
    "As before we will compare networks pretrained with this type of noise using $L_1$ and $L_2$ losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise image with both models\n",
    "from models import DnCNN\n",
    "from skimage import io\n",
    "from denoising_helpers import test_denoiser, PSNR\n",
    "from vistools import unzip\n",
    "\n",
    "p=0.4\n",
    "im_clean = io.imread('datasets/BSD68/test002.png', dtype='float32') \n",
    "mask = np.random.binomial(1, 1-p, im_clean.shape)\n",
    "noise = np.random.uniform(0, 255., im_clean.shape)\n",
    "im_noisy = im_clean * mask + noise * (1 - mask)\n",
    "\n",
    "outputs = list()\n",
    "\n",
    "outputs.append((im_noisy, 'noisy input with sigma = %f' % (sigma)))\n",
    "outputs.append((im_clean, 'clean image'))\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_l1_usp_2000.pt' , map_location=loadmap)[0]\n",
    "out = test_denoiser(net, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append((out, 'dncnn usp l1 loss - PSNR = %f' % PSNR(out, im_clean)))\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_l2_usp_2000.pt' , map_location=loadmap)[0]\n",
    "out = test_denoiser(net, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append((out, 'dncnn usp l2 loss - PSNR = %f' % PSNR(out, im_clean)))\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_l2_2000.pt' , map_location=loadmap)[0]\n",
    "out = test_denoiser(net, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append((out, 'dncnn gaussian MSE loss - PSNR = %f' % PSNR(out, im_clean)))\n",
    "\n",
    "vistools.display_gallery(unzip(outputs,0), unzip(outputs,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that both losses behave roughly the same for both types of considered noise. We will see a different training setup, in which the choice of the loss is crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise to noise training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now follow the training approached proposed in\n",
    "\n",
    "*Noise2Noise: Learning Image Restoration without Clean Data*<br/>\n",
    "J. Lehtinen, J. Munkberg, J. Hasselgren, S. Laine, T. Karras, M. Aittala, T. Aila. In ICML 2018.\n",
    "\n",
    "The idea is here is to compute the loss between two noise realizations of the same clean image. To train\n",
    "with this approach, we pass the flag `noise2noise=True` to the data loader. The data loader will then return pairs of noisy images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoising_dataloaders import train_val_denoising_dataloaders\n",
    "import vistools\n",
    "\n",
    "# noise level\n",
    "p = 40\n",
    "\n",
    "# create the data loader - note 'noise_type' argument\n",
    "train_loader, val_loader = \\\n",
    "    train_val_denoising_dataloaders('./datasets/Train400/',\n",
    "                                     noise_sigma=p,\n",
    "                                     crop_size=40,\n",
    "                                     train_batch_size=16,\n",
    "                                     noise_type='gaussian',\n",
    "                                     noise2noise=True)\n",
    "\n",
    "# visualize first mini-batch\n",
    "X, Y = list(train_loader)[0]\n",
    "\n",
    "# this helper function displays the patches in the mini-batch\n",
    "print('\\n\\nA minibatch of noisy patches:')\n",
    "vistools.display_patches(X)\n",
    "\n",
    "print('\\n\\nAnd the corresponding patches with a different realization of the noise:')\n",
    "vistools.display_patches(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DnCNN\n",
    "from denoising_dataloaders import train_val_denoising_dataloaders\n",
    "from training import trainmodel\n",
    "\n",
    "p=30\n",
    "\n",
    "loss_name = 'l1'\n",
    "#loss_name = 'l2'\n",
    "\n",
    "# DO NOT set this flag to true if running on the server.\n",
    "# The results are already pre-computed.\n",
    "training=False\n",
    "\n",
    "if training: \n",
    "    # data\n",
    "    train_loader, val_loader = train_val_denoising_dataloaders(\n",
    "                                              './datasets/Train400/',\n",
    "                                               noise_sigma=p, crop_size=40, \n",
    "                                               train_batch_size=128,\n",
    "                                               noise_type='gaussian',\n",
    "                                               noise2noise=True)\n",
    "\n",
    "    # network model\n",
    "    dncnn = DnCNN(in_channels=1, out_channels=1, \n",
    "                  num_layers=7, features=13, kernel_size=3, residual=True)\n",
    "\n",
    "    # run the training loop\n",
    "    loss = nn.L1Loss() if loss_name == 'l1' else nn.MSELoss()\n",
    "    dncnn, losst, lossv = trainmodel(dncnn, loss, train_loader, val_loader, \n",
    "                                    num_epochs=2000, save_every=500, loss_every=100,  \n",
    "                                    learning_rate=0.01, weight_decay=0.00001,\n",
    "                                    filename='pre-trained-tp2/tiny_DnCNN_n2n_%s_' % loss_name)\n",
    "\n",
    "    # plot loss\n",
    "    plt.semilogy(lossv, label='val')\n",
    "    plt.semilogy(losst, label='train')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian noise denoisers trained with $L_1$ and $L_2$ losses and noisy targets\n",
    "\n",
    "We have trained our tiny DnCNN network with the MSE (or squared L2 loss) and the L1 loss following the noise2noise approach. Let's compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise image with both models\n",
    "from models import DnCNN\n",
    "from skimage import io\n",
    "from denoising_helpers import test_denoiser, PSNR\n",
    "from vistools import unzip\n",
    "\n",
    "sigma=30\n",
    "im_clean = io.imread('datasets/BSD68/test002.png', dtype='float32') \n",
    "im_noisy = im_clean + np.random.normal(0, sigma, im_clean.shape)\n",
    "\n",
    "outputs = list()\n",
    "\n",
    "outputs.append((im_clean, 'clean image'))\n",
    "outputs.append((im_noisy, 'noisy input with sigma = %f' % (sigma)))\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_n2n_l2_2000.pt' , map_location=loadmap)[0]\n",
    "out = test_denoiser(net, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append((out, 'l2 loss, n2n training - PSNR = %f' % PSNR(out, im_clean)))\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_n2n_l1_2000.pt' , map_location=loadmap)[0]\n",
    "out = test_denoiser(net, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append((out, 'l1 loss, n2n training - PSNR = %f' % PSNR(out, im_clean)))\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_l1_2000.pt' , map_location=loadmap)[0]\n",
    "out = test_denoiser(net, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append((out, 'l1 loss - PSNR = %f' % PSNR(out, im_clean)))\n",
    "\n",
    "vistools.display_gallery(unzip(outputs,0), unzip(outputs,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform S&P noise denoisers trained with $L_1$ and $L_2$ losses and noisy targets\n",
    "\n",
    "We have trained our tiny DnCNN network with the MSE (or squared L2 loss) and the L1 loss following the noise2noise approach. Let's compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise image with both models\n",
    "from models import FFDNet, FFDNet_pretrained_grayscale\n",
    "from models import DnCNN, DnCNN_pretrained\n",
    "from skimage import io\n",
    "from denoising_helpers import test_denoiser, PSNR\n",
    "\n",
    "p=0.4\n",
    "im_clean = io.imread('datasets/BSD68/test006.png', dtype='float32') \n",
    "mask = np.random.binomial(1, 1-p, im_clean.shape)\n",
    "noise = 255. * np.random.uniform(0, 1, im_clean.shape)\n",
    "im_noisy = im_clean * mask + noise * (1 - mask)\n",
    "\n",
    "\n",
    "outputs = list()\n",
    "\n",
    "outputs.append((im_clean, 'clean image'))\n",
    "outputs.append((im_noisy, 'noisy input with sigma = %f' % (sigma)))\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_n2n_l2_usp_2000.pt' , map_location=loadmap)[0]\n",
    "out = test_denoiser(net, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append((out, 'l2 loss, n2n training - PSNR = %f' % PSNR(out, im_clean)))\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_n2n_l1_usp_2000.pt' , map_location=loadmap)[0]\n",
    "out = test_denoiser(net, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append((out, 'l1 loss, n2n training - PSNR = %f' % PSNR(out, im_clean)))\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_l1_usp_2000.pt' , map_location=loadmap)[0]\n",
    "out = test_denoiser(net, im_noisy, None, has_noise=True)[0]\n",
    "outputs.append((out, 'l1 loss - PSNR = %f' % PSNR(out, im_clean)))\n",
    "\n",
    "\n",
    "vistools.display_gallery(unzip(outputs,0), unzip(outputs,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** When training using noisy targets with Gaussian noise, is there any difference between the results obtained with both losses? What about the uniform S&P noise? Give an explanation for this behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER TO QUESTION 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "[//]: # (© 2018 Gabriele Facciolo and Pablo Arias)\n",
    "[//]: # (<div style=\"text-align:center; font-size:75%;\"> Copyright © 2018 Gabriele Facciolo and Pablo Arias. All rights reserved.</div> )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
